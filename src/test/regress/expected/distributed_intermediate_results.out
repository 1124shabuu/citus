-- Test functions for partitioning intermediate results
CREATE SCHEMA distributed_intermediate_results;
SET search_path TO 'distributed_intermediate_results';
SET citus.next_shard_id TO 4213581;
--
-- We don't have extensive tests for partition_task_results, since it will be
-- tested by higher level "INSERT/SELECT with repartitioning" tests anyway.
--
--
-- partition_task_list_results, hash partitioning, binary format
--
CREATE TABLE source_table(a int);
SET citus.shard_count TO 3;
SELECT create_distributed_table('source_table', 'a');
 create_distributed_table
---------------------------------------------------------------------

(1 row)

INSERT INTO source_table SELECT * FROM generate_series(1, 100);
CREATE TABLE target_table(a int);
SET citus.shard_count TO 2;
SELECT create_distributed_table('target_table', 'a');
 create_distributed_table
---------------------------------------------------------------------

(1 row)

-- should error out
SELECT partition_task_list_results('test', $$ SELECT avg(a) FROM source_table $$, 'target_table');
ERROR:  query must be distributed and shouldn't require any merging on the coordinator.
SELECT partition_task_list_results('test', $$ SELECT * FROM generate_series(1, 2) $$, 'target_table');
ERROR:  query must be distributed and shouldn't require any merging on the coordinator.
BEGIN;
CREATE TABLE distributed_result_info AS
  SELECT resultId, nodeport, rowcount, targetShardId, targetShardIndex
  FROM partition_task_list_results('test', $$ SELECT * FROM source_table $$, 'target_table')
          NATURAL JOIN pg_dist_node;
SELECT * FROM distributed_result_info ORDER BY resultId;
        resultid        | nodeport | rowcount | targetshardid | targetshardindex
---------------------------------------------------------------------
 test_from_4213581_to_0 |    57637 |       33 |       4213584 |                0
 test_from_4213582_to_0 |    57638 |       16 |       4213584 |                0
 test_from_4213582_to_1 |    57638 |       15 |       4213585 |                1
 test_from_4213583_to_1 |    57637 |       36 |       4213585 |                1
(4 rows)

-- fetch from workers
SELECT nodeport, fetch_intermediate_results((array_agg(resultId)), 'localhost', nodeport) > 0 AS fetched
  FROM distributed_result_info GROUP BY nodeport ORDER BY nodeport;
 nodeport | fetched
---------------------------------------------------------------------
    57637 | t
    57638 | t
(2 rows)

-- read all fetched result files
SELECT count(*), sum(x) FROM
  read_intermediate_results((SELECT array_agg(resultId) FROM distributed_result_info),
                            'binary') AS res (x int);
 count | sum
---------------------------------------------------------------------
   100 | 5050
(1 row)

END;
DROP TABLE source_table, target_table, distributed_result_info;
--
-- partition_task_list_results, range partitioning, text format
--
CREATE TABLE source_table(a int);
SELECT create_distributed_table('source_table', 'a', 'range');
 create_distributed_table
---------------------------------------------------------------------

(1 row)

CALL public.create_range_partitioned_shards('source_table',
                                            '{0,25,50,76}',
                                            '{24,49,75,200}');
INSERT INTO source_table SELECT * FROM generate_series(1, 100);
CREATE TABLE target_table(a int);
SELECT create_distributed_table('target_table', 'a', 'range');
 create_distributed_table
---------------------------------------------------------------------

(1 row)

CALL public.create_range_partitioned_shards('target_table',
                                            '{0,25,50,76}',
                                            '{24,49,75,200}');
BEGIN;
CREATE TABLE distributed_result_info AS
  SELECT resultId, nodeport, rowcount, targetShardId, targetShardIndex
  FROM partition_task_list_results('test', $$ SELECT (3 * a * a) % 100 FROM source_table $$,
                                   'target_table', false)
          NATURAL JOIN pg_dist_node;
SELECT * FROM distributed_result_info ORDER BY resultId;
        resultid        | nodeport | rowcount | targetshardid | targetshardindex
---------------------------------------------------------------------
 test_from_4213586_to_0 |    57638 |        7 |       4213590 |                0
 test_from_4213586_to_1 |    57638 |        6 |       4213591 |                1
 test_from_4213586_to_2 |    57638 |        7 |       4213592 |                2
 test_from_4213586_to_3 |    57638 |        4 |       4213593 |                3
 test_from_4213587_to_0 |    57637 |        7 |       4213590 |                0
 test_from_4213587_to_1 |    57637 |        6 |       4213591 |                1
 test_from_4213587_to_2 |    57637 |        8 |       4213592 |                2
 test_from_4213587_to_3 |    57637 |        4 |       4213593 |                3
 test_from_4213588_to_0 |    57638 |        8 |       4213590 |                0
 test_from_4213588_to_1 |    57638 |        6 |       4213591 |                1
 test_from_4213588_to_2 |    57638 |        8 |       4213592 |                2
 test_from_4213588_to_3 |    57638 |        4 |       4213593 |                3
 test_from_4213589_to_0 |    57637 |        8 |       4213590 |                0
 test_from_4213589_to_1 |    57637 |        6 |       4213591 |                1
 test_from_4213589_to_2 |    57637 |        7 |       4213592 |                2
 test_from_4213589_to_3 |    57637 |        4 |       4213593 |                3
(16 rows)

-- fetch from workers
SELECT nodeport, fetch_intermediate_results((array_agg(resultId)), 'localhost', nodeport) > 0 AS fetched
  FROM distributed_result_info GROUP BY nodeport ORDER BY nodeport;
 nodeport | fetched
---------------------------------------------------------------------
    57637 | t
    57638 | t
(2 rows)

-- Read all fetched result files. Sum(x) should be 4550, verified by
-- racket -e '(for/sum ([i (range 1 101)]) (modulo (* 3 i i) 100))'
SELECT count(*), sum(x) FROM
  read_intermediate_results((SELECT array_agg(resultId) FROM distributed_result_info),
                            'text') AS res (x int);
 count | sum
---------------------------------------------------------------------
   100 | 4550
(1 row)

END;
DROP TABLE source_table, target_table, distributed_result_info;
SET client_min_messages TO WARNING;
DROP SCHEMA distributed_intermediate_results CASCADE;
\set VERBOSITY default
SET client_min_messages TO DEFAULT;
SET citus.shard_count TO DEFAULT;
